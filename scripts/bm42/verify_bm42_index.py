#!/usr/bin/env python3
"""
BM42 ì¸ë±ì‹± ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ì¸ë±ì‹±ì´ ì˜¬ë°”ë¥´ê²Œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

python3 scripts/verify_bm42_index.py --full --original json/gs_issues.json --report verification_report.json
"""

from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
import json
import numpy as np
from collections import Counter
import argparse
import sys


class BM42IndexVerifier:
    def __init__(self, host="localhost", port=6333):
        """ê²€ì¦ê¸° ì´ˆê¸°í™”"""
        self.client = QdrantClient(host=host, port=port)
        
    def verify_collection(self, collection_name):
        """ì»¬ë ‰ì…˜ ê¸°ë³¸ ì •ë³´ í™•ì¸"""
        try:
            info = self.client.get_collection(collection_name)
            
            print(f"\nğŸ“Š ì»¬ë ‰ì…˜ ì •ë³´: {collection_name}")
            print("=" * 60)
            print(f"ì´ ë¬¸ì„œ ìˆ˜: {info.points_count:,}")
            print(f"ìƒíƒœ: {info.status}")
            
            # Sparse Vector ì„¤ì • í™•ì¸ (ì†ì„± ì¡´ì¬ ì—¬ë¶€ ì²´í¬)
            if hasattr(info.config, 'sparse_vectors_config') and info.config.sparse_vectors_config:
                print(f"\nğŸ”§ Sparse Vector ì„¤ì •:")
                for name, config in info.config.sparse_vectors_config.items():
                    if hasattr(config, 'modifier'):
                        print(f"  - {name}: IDF modifier = {config.modifier}")
                    else:
                        print(f"  - {name}: Sparse vector ì„¤ì •ë¨")
                    
            return info.points_count
            
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ {collection_name}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return 0
            
    def analyze_sample_documents(self, collection_name, sample_size=10):
        """ìƒ˜í”Œ ë¬¸ì„œ ë¶„ì„"""
        print(f"\nğŸ” ìƒ˜í”Œ ë¬¸ì„œ ë¶„ì„ (ìƒìœ„ {sample_size}ê°œ)")
        print("=" * 60)
        
        try:
            # ìƒ˜í”Œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
            samples = self.client.retrieve(
                collection_name=collection_name,
                ids=list(range(sample_size)),
                with_vectors=["bm42"],
                with_payload=True
            )
            
            token_counts = []
            value_stats = []
            
            for point in samples:
                print(f"\nğŸ“„ ë¬¸ì„œ ID: {point.id}")
                print(f"   Key: {point.payload.get('key', 'N/A')}")
                
                title = point.payload.get('title', '')
                if title:
                    print(f"   ì œëª©: {title[:80]}...")
                    
                if "bm42" in point.vector:
                    sparse = point.vector["bm42"]
                    num_tokens = len(sparse.indices)
                    token_counts.append(num_tokens)
                    
                    if sparse.values:
                        values = sparse.values
                        value_stats.extend(values)
                        
                        print(f"   í† í° ìˆ˜: {num_tokens}")
                        print(f"   ìµœëŒ€ ì ìˆ˜: {max(values):.4f}")
                        print(f"   í‰ê·  ì ìˆ˜: {np.mean(values):.4f}")
                        print(f"   ìƒìœ„ 5ê°œ ì ìˆ˜: {sorted(values, reverse=True)[:5]}")
                        
            # ì „ì²´ í†µê³„
            if token_counts:
                print(f"\nğŸ“ˆ ì „ì²´ í†µê³„:")
                print(f"   í‰ê·  í† í° ìˆ˜: {np.mean(token_counts):.1f}")
                print(f"   í† í° ìˆ˜ ë²”ìœ„: {min(token_counts)} ~ {max(token_counts)}")
                
            if value_stats:
                print(f"   ì „ì²´ í‰ê·  ì ìˆ˜: {np.mean(value_stats):.4f}")
                print(f"   ì ìˆ˜ í‘œì¤€í¸ì°¨: {np.std(value_stats):.4f}")
                
        except Exception as e:
            print(f"âŒ ìƒ˜í”Œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            
    def test_search_functionality(self, collection_name):
        """ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ§ª ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        
        test_queries = [
            ("EDR", "ë„ë©”ì¸ íŠ¹í™” ìš©ì–´"),
            ("ë³´ì•ˆ", "í•œêµ­ì–´ ì¼ë°˜ ìš©ì–´"),
            ("security", "ì˜ì–´ ì¼ë°˜ ìš©ì–´"),
            ("Live Response", "ë³µí•© ìš©ì–´"),
            ("API ì¸ì¦ ì˜¤ë¥˜", "í•œêµ­ì–´ + ì˜ì–´ í˜¼í•©"),
        ]
        
        from fastembed import SparseTextEmbedding
        model = SparseTextEmbedding("Qdrant/bm42-all-minilm-l6-v2-attentions")
        
        for query, description in test_queries:
            print(f"\nğŸ” í…ŒìŠ¤íŠ¸: '{query}' ({description})")
            
            try:
                # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
                query_embedding = list(model.embed([query]))[0]
                
                from qdrant_client.models import SparseVector, NamedSparseVector
                
                query_vector = SparseVector(
                    indices=query_embedding.indices.tolist(),
                    values=query_embedding.values.tolist()
                )
                
                # ê²€ìƒ‰ ì‹¤í–‰
                results = self.client.search(
                    collection_name=collection_name,
                    query_vector=NamedSparseVector(
                        name="bm42",
                        vector=query_vector
                    ),
                    limit=3
                )
                
                print(f"   í† í° ìˆ˜: {len(query_embedding.indices)}")
                print(f"   ê²°ê³¼ ìˆ˜: {len(results)}")
                
                for i, result in enumerate(results[:3], 1):
                    print(f"   {i}. [{result.payload.get('key')}] Score: {result.score:.4f}")
                    
            except Exception as e:
                print(f"   âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
    def verify_data_integrity(self, collection_name, original_file=None):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        print(f"\nâœ… ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦")
        print("=" * 60)
        
        # Qdrantì˜ ë¬¸ì„œ ìˆ˜
        qdrant_count = self.client.get_collection(collection_name).points_count
        print(f"Qdrant ë¬¸ì„œ ìˆ˜: {qdrant_count:,}")
        
        # ì›ë³¸ íŒŒì¼ê³¼ ë¹„êµ
        if original_file:
            try:
                with open(original_file, 'r', encoding='utf-8') as f:
                    original_data = json.load(f)
                original_count = len(original_data)
                print(f"ì›ë³¸ íŒŒì¼ ë¬¸ì„œ ìˆ˜: {original_count:,}")
                
                if qdrant_count == original_count:
                    print("âœ… ë¬¸ì„œ ìˆ˜ ì¼ì¹˜!")
                else:
                    diff = abs(qdrant_count - original_count)
                    print(f"âš ï¸ ë¬¸ì„œ ìˆ˜ ë¶ˆì¼ì¹˜: {diff}ê°œ ì°¨ì´")
                    
                # ìƒ˜í”Œ í‚¤ í™•ì¸
                if original_data and 'key' in original_data[0]:
                    sample_keys = [doc.get('key') for doc in original_data[:5] if 'key' in doc]
                    print(f"\nì›ë³¸ ìƒ˜í”Œ í‚¤: {sample_keys}")
                    
                    # Qdrantì—ì„œ ë™ì¼í•œ í‚¤ ê²€ìƒ‰
                    for key in sample_keys:
                        filter_condition = Filter(
                            must=[
                                FieldCondition(
                                    key="key",
                                    match=MatchValue(value=key)
                                )
                            ]
                        )
                        
                        results = self.client.scroll(
                            collection_name=collection_name,
                            scroll_filter=filter_condition,
                            limit=1
                        )[0]
                        
                        if results:
                            print(f"  âœ… {key} ì¡´ì¬")
                        else:
                            print(f"  âŒ {key} ì—†ìŒ")
                            
            except Exception as e:
                print(f"âŒ ì›ë³¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                
    def generate_report(self, collection_name, output_file=None):
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        report = {
            "collection": collection_name,
            "verification_results": {},
            "recommendations": []
        }
        
        # ê¸°ë³¸ ì •ë³´
        count = self.verify_collection(collection_name)
        report["verification_results"]["document_count"] = count
        
        if count == 0:
            report["recommendations"].append("ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¸ë±ì‹±ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        elif count < 100:
            report["recommendations"].append("ë¬¸ì„œ ìˆ˜ê°€ ì ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ë¥¼ ì¸ë±ì‹±í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")
            
        # ë³´ê³ ì„œ ì¶œë ¥
        print(f"\nğŸ“‹ ê²€ì¦ ë³´ê³ ì„œ")
        print("=" * 60)
        print(f"ì»¬ë ‰ì…˜: {collection_name}")
        print(f"ë¬¸ì„œ ìˆ˜: {count:,}")
        
        if report["recommendations"]:
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in report["recommendations"]:
                print(f"  - {rec}")
                
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"\në³´ê³ ì„œ ì €ì¥: {output_file}")
            
        return report


def main():
    parser = argparse.ArgumentParser(description="BM42 ì¸ë±ìŠ¤ ê²€ì¦")
    parser.add_argument("--collection", "-c", default="jira_bm42_full", 
                        help="ê²€ì¦í•  ì»¬ë ‰ì…˜ ì´ë¦„")
    parser.add_argument("--host", default="localhost", help="Qdrant í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--port", type=int, default=6333, help="Qdrant í¬íŠ¸")
    parser.add_argument("--original", "-o", help="ì›ë³¸ JSON íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--report", "-r", help="ë³´ê³ ì„œ ì¶œë ¥ íŒŒì¼")
    parser.add_argument("--full", action="store_true", help="ì „ì²´ ê²€ì¦ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    # ê²€ì¦ê¸° ì´ˆê¸°í™”
    verifier = BM42IndexVerifier(args.host, args.port)
    
    # ê¸°ë³¸ ê²€ì¦
    count = verifier.verify_collection(args.collection)
    
    if count > 0:
        # ìƒ˜í”Œ ë¶„ì„
        verifier.analyze_sample_documents(args.collection)
        
        if args.full:
            # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            verifier.test_search_functionality(args.collection)
            
            # ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
            if args.original:
                verifier.verify_data_integrity(args.collection, args.original)
                
        # ë³´ê³ ì„œ ìƒì„±
        verifier.generate_report(args.collection, args.report)
        
    else:
        print(f"\nâŒ ì»¬ë ‰ì…˜ {args.collection}ì´ ë¹„ì–´ìˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        sys.exit(1)


if __name__ == "__main__":
    main()